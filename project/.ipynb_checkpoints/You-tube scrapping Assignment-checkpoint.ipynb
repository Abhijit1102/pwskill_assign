{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3ba64cc",
   "metadata": {},
   "source": [
    "# Go to this given URL and solve the following questions\n",
    "# URL: https://www.youtube.com/@PW-Foundation/videos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6391fec",
   "metadata": {},
   "source": [
    "# Q1. Write a python program to extract the video URL of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6a4f609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.youtube.com/watch?v=hzwEXoQDNCs',\n",
       " 'https://www.youtube.com/watch?v=0s6hAsFGxYE',\n",
       " 'https://www.youtube.com/watch?v=YXRyMc_noiE',\n",
       " 'https://www.youtube.com/watch?v=PI1obes98Zc',\n",
       " 'https://www.youtube.com/watch?v=16fUsD0M1-I']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "html = requests.get(url).text\n",
    "\n",
    "video_ids = re.findall(r\"watch\\?v=(\\S{11})\", html)\n",
    "\n",
    "video_links = [\"https://www.youtube.com/watch?v=\" + id for id in video_ids]\n",
    "\n",
    "urls = video_links[:5]\n",
    "\n",
    "urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bf30df",
   "metadata": {},
   "source": [
    "# Q2. Write a python program to extract the URL of the video thumbnails of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c7f5919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://i.ytimg.com/vi/hzwEXoQDNCs/maxresdefault.jpg\n",
      "https://i.ytimg.com/vi/0s6hAsFGxYE/maxresdefault.jpg\n",
      "https://i.ytimg.com/vi/YXRyMc_noiE/maxresdefault.jpg\n",
      "https://i.ytimg.com/vi/PI1obes98Zc/maxresdefault.jpg\n",
      "https://i.ytimg.com/vi/16fUsD0M1-I/maxresdefault.jpg\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "for url in urls:\n",
    "\n",
    "    # Extract video ID from URL\n",
    "    exp = \"^.*((youtu.be\\/)|(v\\/)|(\\/u\\/\\w\\/)|(embed\\/)|(watch\\?))\\??v?=?([^#&?]*).*\"\n",
    "    s = re.findall(exp, url)[0][-1]\n",
    "\n",
    "    # Construct image URL\n",
    "    thumbnail_url = f\"https://i.ytimg.com/vi/{s}/maxresdefault.jpg\"\n",
    "\n",
    "    print(thumbnail_url)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83149d50",
   "metadata": {},
   "source": [
    "# Q3. Write a python program to extract the Title of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d977fc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------Title---------------------------------------\n",
      "TitlesAarambh Batch 2024 | For CBSE Class 11th Commerce | Biggest LaunchðŸ”¥\n",
      "---------------------------------------Title---------------------------------------\n",
      "TitlesIndia's NO.1 Batch for Class 10th - UDAAN âš¡ Launching Today !! Check Description.\n",
      "---------------------------------------Title---------------------------------------\n",
      "TitlesIndia's Biggest Scholarship Test for Classes 8th to 12th !! ðŸ”¥ðŸ”¥ || PW SAT 2023 âš¡ðŸ’¥\n",
      "---------------------------------------Title---------------------------------------\n",
      "TitlesHow to score 95%+ in class 10th? Complete year Powerful Strategy!!\n",
      "---------------------------------------Title---------------------------------------\n",
      "TitlesLast 4 Days Left For SST Exam || How To Manage to Score 80/80 in Boards || Class-10th\n"
     ]
    }
   ],
   "source": [
    "from requests_html import HTMLSession\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "\n",
    "def give_me_everything():\n",
    "\n",
    "    data = soup.find_all(\"meta\") \n",
    "\n",
    "    for i in range(len(data)):  \n",
    "        print(data[i])\n",
    "\n",
    "for url  in urls:\n",
    "   \n",
    "    session = HTMLSession() \n",
    "    response = session.get(url)  \n",
    "\n",
    "    if response.status_code != 200: \n",
    "        print(\"Error! Response = \" + str(response.status_code))\n",
    "    else:\n",
    "        soup = bs(response.content, \"html.parser\")  \n",
    "\n",
    "        print(\"---------------------------------------Title---------------------------------------\")\n",
    "        \n",
    "        print(\"Titles\" + soup.find(\"meta\", property=\"og:title\")[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae33ab65",
   "metadata": {},
   "source": [
    "# Q4. Write a python program to extract the number of views of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "609e8fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------Views---------------------------------------\n",
      "views: 27890\n",
      "---------------------------------------Views---------------------------------------\n",
      "views: 62035\n",
      "---------------------------------------Views---------------------------------------\n",
      "views: 78917\n",
      "---------------------------------------Views---------------------------------------\n",
      "views: 277291\n",
      "---------------------------------------Views---------------------------------------\n",
      "views: 69366\n"
     ]
    }
   ],
   "source": [
    "for url in urls:\n",
    "   \n",
    "    session = HTMLSession() \n",
    "    response = session.get(url)  \n",
    "\n",
    "    if response.status_code != 200: \n",
    "        print(\"Error! Response = \" + str(response.status_code))\n",
    "    else:\n",
    "        soup = bs(response.content, \"html.parser\")  \n",
    "\n",
    "        \n",
    "        print(\"---------------------------------------Views---------------------------------------\")\n",
    "       \n",
    "        \n",
    "        print(\"views: \" + soup.find(\"meta\", itemprop=\"interactionCount\")[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fb7b62",
   "metadata": {},
   "source": [
    "# Q5. Write a python program to extract the time of posting of video for the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1268830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------Date of Publish---------------------------------------\n",
      "Published Date: 2023-03-27\n",
      "---------------------------------------Date of Publish---------------------------------------\n",
      "Published Date: 2023-03-22\n",
      "---------------------------------------Date of Publish---------------------------------------\n",
      "Published Date: 2023-03-21\n",
      "---------------------------------------Date of Publish---------------------------------------\n",
      "Published Date: 2023-03-10\n",
      "---------------------------------------Date of Publish---------------------------------------\n",
      "Published Date: 2023-03-10\n"
     ]
    }
   ],
   "source": [
    "for url in urls:\n",
    "   \n",
    "    session = HTMLSession() \n",
    "    response = session.get(url)  \n",
    "\n",
    "    if response.status_code != 200: \n",
    "        print(\"Error! Response = \" + str(response.status_code))\n",
    "    else:\n",
    "        soup = bs(response.content, \"html.parser\")  \n",
    "\n",
    "        print(\"---------------------------------------Date of Publish---------------------------------------\")\n",
    "        \n",
    "        print(\"Published Date: \" + soup.find(\"meta\", itemprop=\"uploadDate\")[\"content\"])\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211e3d24",
   "metadata": {},
   "source": [
    "**Note: Save all the data scraped in the above questions in a CSV file.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd30464",
   "metadata": {},
   "source": [
    "## Create a simple UI with all functionalities mentioned above and deploy it in AWS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c801c127",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='Screenshot (2).png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de70b3d2",
   "metadata": {},
   "source": [
    "# Note: Create your assignment in Jupyter notebook and upload it to GitHub & share that uploaded assignment file link through your dashboard. Make sure the repository is public. Submit your deployment link as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fb41a9",
   "metadata": {},
   "source": [
    "### AWS deployment link : http://scapy-env-1.eba-qexp2uwb.ap-northeast-1.elasticbeanstalk.com/\n",
    "### GIthub link :  https://github.com/Abhijit1102/youtube-scapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862ea959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8224295",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
